{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import set_seed\n",
    "from itertools import permutations\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, set_seed\n",
    "\n",
    "# 시드 고정 함수\n",
    "def set_all_seeds(seed=42):\n",
    "    \"\"\"모든 라이브러리 시드 고정\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    set_seed(seed)  # Transformers 시드 고정\n",
    "\n",
    "# 시드 고정\n",
    "set_all_seeds(42)\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc95461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "test = pd.read_csv('/content/drive/MyDrive/project/sentence/data/test.csv')\n",
    "submission = pd.read_csv('/content/drive/MyDrive/project/sentence/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d04cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델과 토크나이저 로드\n",
    "bert_output_dir = f\"/content/drive/MyDrive/project/sentence/bert-kor-base-pt\"\n",
    "roberta_output_dir = f\"/content/drive/MyDrive/project/sentence/roberta-large-pt\"\n",
    "electra_output_dir = f\"/content/drive/MyDrive/project/sentence/electra-kor-base-pt\"\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_output_dir)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(bert_output_dir)\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_output_dir)\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(roberta_output_dir)\n",
    "\n",
    "electra_tokenizer = AutoTokenizer.from_pretrained(electra_output_dir)\n",
    "electra_model = AutoModelForSequenceClassification.from_pretrained(electra_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac60388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델들을 디바이스로 이동\n",
    "bert_model.to(device).eval()\n",
    "roberta_model.to(device).eval()\n",
    "electra_model.to(device).eval()\n",
    "\n",
    "# 데이터셋 클래스 (예측용)\n",
    "class SentenceOrderDataset(Dataset):\n",
    "    def __init__(self, pairs, tokenizer, max_len):\n",
    "        self.pairs = pairs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sent_A, sent_B = self.pairs[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sent_A, sent_B,\n",
    "            add_special_tokens=True, max_length=self.max_len,\n",
    "            padding='max_length', truncation=True,\n",
    "            return_token_type_ids=True, return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'token_type_ids': encoding['token_type_ids'].flatten()\n",
    "        }\n",
    "\n",
    "# 예측 함수\n",
    "def predict_probabilities(model, tokenizer, sentence_pairs, device, max_length=256, batch_size=64):\n",
    "    \"\"\"문장 쌍에 대한 예측 확률 반환\"\"\"\n",
    "    all_probs = []\n",
    "\n",
    "    dataset = SentenceOrderDataset(sentence_pairs, tokenizer, max_length)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "    return np.array(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e049ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 순서 예측 함수 수정\n",
    "def predict_sentence_order_ensemble_with_probs(sentences, models, tokenizers, device, weights=None):\n",
    "    \"\"\"앙상블로 문장 순서를 예측하고 확률 정보 반환\"\"\"\n",
    "    if weights is None:\n",
    "        weights = [1.0/len(models)] * len(models)\n",
    "\n",
    "    all_perms = list(permutations(range(4)))\n",
    "    perm_scores = np.zeros(len(all_perms))\n",
    "\n",
    "    for perm_idx, perm in enumerate(all_perms):\n",
    "        pairs = []\n",
    "        for i in range(3):\n",
    "            pairs.append((sentences[perm[i]], sentences[perm[i+1]]))\n",
    "\n",
    "        model_scores = []\n",
    "        for model, tokenizer in zip(models, tokenizers):\n",
    "            probs = predict_probabilities(model, tokenizer, pairs, device)\n",
    "            model_score = np.prod(probs)\n",
    "            model_scores.append(model_score)\n",
    "\n",
    "        perm_scores[perm_idx] = np.average(model_scores, weights=weights)\n",
    "\n",
    "    # 정규화하여 확률로 변환\n",
    "    perm_probs = perm_scores / perm_scores.sum()\n",
    "\n",
    "    best_perm_idx = np.argmax(perm_scores)\n",
    "    best_perm = list(all_perms[best_perm_idx])\n",
    "    best_prob = perm_probs[best_perm_idx]\n",
    "\n",
    "    return best_perm, best_prob, perm_probs, all_perms\n",
    "\n",
    "# 테스트 데이터 예측 (확률 포함)\n",
    "predictions = []\n",
    "confidence_scores = []\n",
    "\n",
    "print(\"테스트 데이터 예측 시작...\")\n",
    "for idx, row in tqdm(test.iterrows(), total=len(test)):\n",
    "    sentences = [row[f'sentence_{i}'] for i in range(4)]\n",
    "\n",
    "    predicted_order, confidence, all_probs, all_perms = predict_sentence_order_ensemble_with_probs(\n",
    "        sentences, models, tokenizers, device, weights\n",
    "    )\n",
    "\n",
    "    predictions.append(predicted_order)\n",
    "    confidence_scores.append(confidence)\n",
    "\n",
    "    # 상위 3개 순열 출력 (디버깅용)\n",
    "    if idx < 5:  # 처음 5개만 출력\n",
    "        print(f\"\\n샘플 {idx}:\")\n",
    "        sorted_indices = np.argsort(all_probs)[::-1][:3]\n",
    "        for rank, idx_perm in enumerate(sorted_indices):\n",
    "            print(f\"  {rank+1}위: {list(all_perms[idx_perm])} - {all_probs[idx_perm]:.4%}\")\n",
    "\n",
    "# 평균 신뢰도 출력\n",
    "print(f\"\\n평균 예측 신뢰도: {np.mean(confidence_scores):.4%}\")\n",
    "print(f\"최소 신뢰도: {np.min(confidence_scores):.4%}\")\n",
    "print(f\"최대 신뢰도: {np.max(confidence_scores):.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f4fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 완료 후 신뢰도 분석\n",
    "# 1. 히스토그램 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(confidence_scores, bins=10, range=(0, 1), edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('예측 신뢰도 (%)')\n",
    "plt.ylabel('데이터 개수')\n",
    "plt.title('테스트 데이터 예측 신뢰도 분포')\n",
    "\n",
    "# x축을 백분율로 표시\n",
    "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x*100)}%'))\n",
    "\n",
    "# 각 구간에 개수 표시\n",
    "counts, bins, patches = plt.hist(confidence_scores, bins=10, range=(0, 1), edgecolor='black', alpha=0.7)\n",
    "for count, bin_center, patch in zip(counts, (bins[:-1] + bins[1:]) / 2, patches):\n",
    "    plt.text(bin_center, count + max(counts)*0.01, f'{int(count)}',\n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. 구간별 개수 데이터프레임\n",
    "confidence_df = pd.DataFrame({\n",
    "    '신뢰도 구간': [f'{i*10}%-{(i+1)*10}%' for i in range(10)],\n",
    "    '데이터 개수': [0] * 10,\n",
    "    '비율(%)': [0.0] * 10\n",
    "})\n",
    "\n",
    "# 각 구간별로 카운트\n",
    "for score in confidence_scores:\n",
    "    bin_idx = min(int(score * 10), 9)  # 0-9 사이의 인덱스\n",
    "    confidence_df.loc[bin_idx, '데이터 개수'] += 1\n",
    "\n",
    "# 비율 계산\n",
    "total_count = len(confidence_scores)\n",
    "confidence_df['비율(%)'] = (confidence_df['데이터 개수'] / total_count * 100).round(2)\n",
    "\n",
    "# 누적 비율 추가\n",
    "confidence_df['누적 비율(%)'] = confidence_df['비율(%)'].cumsum().round(2)\n",
    "\n",
    "print(\"\\n=== 신뢰도 구간별 분포 ===\")\n",
    "print(confidence_df)\n",
    "\n",
    "# 3. 기초 통계 정보\n",
    "print(\"\\n=== 신뢰도 통계 정보 ===\")\n",
    "print(f\"평균 신뢰도: {np.mean(confidence_scores):.2%}\")\n",
    "print(f\"중앙값: {np.median(confidence_scores):.2%}\")\n",
    "print(f\"표준편차: {np.std(confidence_scores):.2%}\")\n",
    "print(f\"최소값: {np.min(confidence_scores):.2%}\")\n",
    "print(f\"최대값: {np.max(confidence_scores):.2%}\")\n",
    "\n",
    "# 4. 50% 미만 신뢰도를 가진 데이터 분석\n",
    "low_confidence_mask = np.array(confidence_scores) < 0.5\n",
    "low_confidence_count = np.sum(low_confidence_mask)\n",
    "\n",
    "print(f\"\\n50% 미만 신뢰도 데이터: {low_confidence_count}개 ({low_confidence_count/total_count*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5131fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission 데이터프레임에 예측과 신뢰도 추가\n",
    "for i in range(4):\n",
    "    submission[f'answer_{i}'] = [pred[i] for pred in predictions]\n",
    "\n",
    "submission['confidence'] = confidence_scores\n",
    "\n",
    "# 신뢰도가 0.5 이하인 데이터 인덱스 리스트\n",
    "low_confidence_indices = submission[submission['confidence'] <= 0.5].index.tolist()\n",
    "print(f\"신뢰도 0.5 이하인 데이터의 개수: {len(low_confidence_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen3-14B 모델 로드\n",
    "qwen_model_name = \"Qwen/Qwen3-14B\"  # Instruct 버전 사용\n",
    "print(f\"Qwen 모델 로드 중: {qwen_model_name}\")\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(qwen_model_name)\n",
    "qwen_model = AutoModelForCausalLM.from_pretrained(\n",
    "    qwen_model_name,\n",
    "    torch_dtype=torch.float16,  # 메모리 절약\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "print(\"모델 로드 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e5c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen3-14B를 사용한 문장 순서 예측 함수\n",
    "def predict_sentence_order_with_qwen(sentences, model, tokenizer):\n",
    "    \"\"\"Qwen 모델로 직접 문장 순서 예측\"\"\"\n",
    "\n",
    "    # 모든 가능한 순열 생성\n",
    "    all_perms = list(permutations(range(4)))\n",
    "\n",
    "    # 프롬프트 생성 (영어)\n",
    "    prompt = f\"\"\"You are given 4 Korean sentences that are currently in a scrambled order. Your task is to rearrange them in the most natural and logical sequence.\n",
    "\n",
    "[Scrambled Sentences]\n",
    "Sentence 0: {sentences[0]}\n",
    "Sentence 1: {sentences[1]}\n",
    "Sentence 2: {sentences[2]}\n",
    "Sentence 3: {sentences[3]}\n",
    "\n",
    "[Instructions]\n",
    "1. Consider temporal order, cause-and-effect relationships, and logical flow.\n",
    "2. Your answer must be ONLY the sentence numbers separated by commas, like \"0,1,2,3\".\n",
    "3. Do not provide any explanation, just the sequence numbers.\n",
    "\n",
    "The correct order is:\"\"\"\n",
    "\n",
    "    # 토크나이즈\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # 생성\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=20,\n",
    "            temperature=0.1,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # 응답 파싱\n",
    "    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "    try:\n",
    "        # \"0,1,2,3\" 형식에서 순서 추출\n",
    "        order_str = response.strip().split('\\n')[0]  # 첫 줄만 사용\n",
    "        order = [int(x.strip()) for x in order_str.split(',')]\n",
    "\n",
    "        # 유효성 검사\n",
    "        if len(order) == 4 and set(order) == {0, 1, 2, 3}:\n",
    "            return order\n",
    "        else:\n",
    "            print(f\"Invalid response format: {response}\")\n",
    "            # 폴백: 점수 기반 방법 사용\n",
    "            return predict_with_scoring(sentences, model, tokenizer)\n",
    "    except:\n",
    "        print(f\"Parsing failed: {response}\")\n",
    "        return predict_with_scoring(sentences, model, tokenizer)\n",
    "\n",
    "def predict_with_scoring(sentences, model, tokenizer):\n",
    "    \"\"\"점수 기반 예측 (폴백 방법)\"\"\"\n",
    "    all_perms = list(permutations(range(4)))\n",
    "    best_score = -float('inf')\n",
    "    best_perm = list(range(4))\n",
    "\n",
    "    for perm in all_perms[:6]:\n",
    "        # 순열에 따른 텍스트 생성\n",
    "        ordered_text = \" \".join([sentences[i] for i in perm])\n",
    "\n",
    "        prompt = f\"\"\"Please evaluate if the following Korean sentences are logically well-connected in the given order:\n",
    "\n",
    "{ordered_text}\n",
    "\n",
    "Is this sequence natural and coherent? Answer with only 'Yes' or 'No':\"\"\"\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # 마지막 토큰의 logit을 점수로 사용\n",
    "            score = outputs.logits[0, -1, :].max().item()\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_perm = list(perm)\n",
    "\n",
    "    return best_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e153f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신뢰도가 0.5 이하인 데이터 재예측\n",
    "new_predictions = []\n",
    "original_predictions = []  # 기존 예측 저장\n",
    "\n",
    "print(\"\\nQwen 모델로 재예측 시작...\")\n",
    "progress_bar = tqdm(low_confidence_indices, desc=\"Qwen 재예측\")\n",
    "\n",
    "for idx in progress_bar:\n",
    "    # 기존 예측 저장\n",
    "    original_order = [submission.loc[idx, f'answer_{j}'] for j in range(4)]\n",
    "    original_predictions.append(original_order)\n",
    "\n",
    "    test_idx = idx\n",
    "    sentences = [test.iloc[test_idx][f'sentence_{i}'] for i in range(4)]\n",
    "\n",
    "    # Qwen으로 예측\n",
    "    predicted_order = predict_sentence_order_with_qwen(sentences, qwen_model, qwen_tokenizer)\n",
    "    new_predictions.append(predicted_order)\n",
    "\n",
    "    # 진행 상황 업데이트\n",
    "    progress_bar.set_postfix({\n",
    "        \"처리 개수\": f\"{len(new_predictions)}/{len(low_confidence_indices)}\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df6846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 업데이트\n",
    "changed_count = 0\n",
    "changed_indices = []\n",
    "\n",
    "for i, idx in enumerate(low_confidence_indices):\n",
    "    # 변경 여부 확인\n",
    "    if original_predictions[i] != new_predictions[i]:\n",
    "        changed_count += 1\n",
    "        changed_indices.append((idx, i))\n",
    "\n",
    "    # 업데이트\n",
    "    for j in range(4):\n",
    "        submission.loc[idx, f'answer_{j}'] = new_predictions[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be412a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 제출 파일 저장\n",
    "submission_final = submission[['ID', 'answer_0', 'answer_1', 'answer_2', 'answer_3']]\n",
    "submission_final.to_csv('./project/sentence/submission_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
